"""Streamlit ä¸»åº”ç”¨ - PV Pile Integration System."""

import logging
import streamlit as st
from pathlib import Path
from typing import Optional

import config
from src.inference.docker_client import check_container_status, run_docker_inference
from src.inference.result_parser import get_detection_stats, parse_sahi_results
from src.visualization.confidence_colors import get_confidence_emoji
from src.visualization.image_stitcher import create_visualization, image_to_pil

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title=config.STREAMLIT_PAGE_TITLE,
    page_icon=config.STREAMLIT_PAGE_ICON,
    layout="wide",
    initial_sidebar_state="expanded",
)

# ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨
config.ensure_directories()


def main() -> None:
    """ä¸»åº”ç”¨å‡½æ•°."""
    st.title("ğŸ”‹ PV Pile Integration System")
    st.markdown("å…‰ä¼æ¿æ¡©åŸºæ£€æµ‹é›†æˆç³»ç»Ÿ - æ•´åˆ PV Pile å’Œ SolarGeoFix")
    
    # ä¾§è¾¹æ  - å‚æ•°é…ç½®
    with st.sidebar:
        st.header("âš™ï¸ é…ç½®å‚æ•°")
        
        slice_height = st.number_input(
            "åˆ‡ç‰‡é«˜åº¦",
            min_value=128,
            max_value=2048,
            value=config.DEFAULT_SLICE_HEIGHT,
            step=64,
            help="SAHI åˆ‡ç‰‡çš„åƒç´ é«˜åº¦"
        )
        
        slice_width = st.number_input(
            "åˆ‡ç‰‡å®½åº¦",
            min_value=128,
            max_value=2048,
            value=config.DEFAULT_SLICE_WIDTH,
            step=64,
            help="SAHI åˆ‡ç‰‡çš„åƒç´ å®½åº¦"
        )
        
        conf_threshold = st.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼",
            min_value=0.0,
            max_value=1.0,
            value=config.DEFAULT_CONF_THRESHOLD,
            step=0.05,
            help="æ£€æµ‹ç»“æœçš„æœ€å°ç½®ä¿¡åº¦"
        )
        
        overlap_ratio = st.slider(
            "é‡å æ¯”ä¾‹",
            min_value=0.0,
            max_value=0.5,
            value=config.DEFAULT_OVERLAP_RATIO,
            step=0.05,
            help="åˆ‡ç‰‡ä¹‹é—´çš„é‡å æ¯”ä¾‹"
        )
    
    # ä¸»å†…å®¹åŒº
    st.header("ğŸ“¤ å›¾åƒä¸Šä¼ ")
    
    uploaded_file = st.file_uploader(
        "é€‰æ‹©æ— äººæœºæ­£æ‘„èˆªæ‹å›¾åƒ",
        type=["png", "jpg", "jpeg"],
        help="æ”¯æŒ PNG å’Œ JPG æ ¼å¼"
    )
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºä¸Šä¼ çš„å›¾åƒä¿¡æ¯
        file_details = {
            "æ–‡ä»¶å": uploaded_file.name,
            "æ–‡ä»¶ç±»å‹": uploaded_file.type,
            "æ–‡ä»¶å¤§å°": f"{uploaded_file.size / 1024 / 1024:.2f} MB"
        }
        st.json(file_details)
        
        # ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        input_path = config.INPUT_DIR / uploaded_file.name
        with open(input_path, "wb") as f:
            f.write(uploaded_file.getbuffer())
        
        # æ˜¾ç¤ºåŸå›¾
        st.header("ğŸ“· åŸå§‹å›¾åƒ")
        st.image(uploaded_file, use_container_width=True)
        
        # æ¨ç†æŒ‰é’®
        col1, col2, col3 = st.columns([1, 1, 2])
        with col1:
            run_inference = st.button("ğŸš€ è¿è¡Œæ¨ç†", type="primary", use_container_width=True)
        with col2:
            clear_cache = st.button("ğŸ—‘ï¸ æ¸…é™¤ç¼“å­˜", use_container_width=True)
        
        if clear_cache:
            st.cache_data.clear()
            st.success("ç¼“å­˜å·²æ¸…é™¤")
        
        # æ£€æŸ¥å®¹å™¨çŠ¶æ€
        container_status = check_container_status()
        if not container_status:
            st.error(
                f"âš ï¸ Docker å®¹å™¨ '{config.CONTAINER_NAME}' æœªè¿è¡Œã€‚"
                "è¯·å…ˆå¯åŠ¨å®¹å™¨ã€‚"
            )
        
        # è¿è¡Œæ¨ç†
        if run_inference:
            if not container_status:
                st.error("æ— æ³•è¿è¡Œæ¨ç†ï¼šå®¹å™¨æœªè¿è¡Œ")
            else:
                with st.spinner("æ­£åœ¨è¿è¡Œæ¨ç†ï¼Œè¯·ç¨å€™..."):
                    try:
                        # è¿è¡Œ Docker æ¨ç†
                        output_dir = config.OUTPUT_DIR
                        result = run_docker_inference(
                            image_path=input_path,
                            output_dir=output_dir,
                            slice_height=slice_height,
                            slice_width=slice_width,
                            conf_threshold=conf_threshold,
                            overlap_ratio=overlap_ratio,
                        )
                        
                        # è§£æç»“æœ
                        detections = parse_sahi_results(result["json_path"])
                        stats = get_detection_stats(detections)
                        
                        # ä¿å­˜ç»“æœåˆ° session state
                        st.session_state["detections"] = detections
                        st.session_state["stats"] = stats
                        st.session_state["result"] = result
                        st.session_state["input_path"] = input_path
                        
                        st.success(f"âœ… æ¨ç†å®Œæˆï¼æ£€æµ‹åˆ° {stats['total']} ä¸ªç›®æ ‡")
                        
                    except Exception as e:
                        logger.exception("æ¨ç†å¤±è´¥")
                        st.error(f"âŒ æ¨ç†å¤±è´¥: {str(e)}")
        
        # æ˜¾ç¤ºæ¨ç†ç»“æœ
        if "detections" in st.session_state and st.session_state["detections"]:
            detections = st.session_state["detections"]
            stats = st.session_state["stats"]
            input_path = st.session_state["input_path"]
            
            # æ¨ç†ç»“æœå¯è§†åŒ–
            st.header("ğŸ” æ¨ç†ç»“æœ")
            
            # ç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("æ€»æ£€æµ‹æ•°", stats["total"])
            with col2:
                st.metric(
                    f"{get_confidence_emoji(0.8)} é«˜ç½®ä¿¡åº¦",
                    stats["high_confidence"],
                )
            with col3:
                st.metric(
                    f"{get_confidence_emoji(0.5)} ä¸­ç½®ä¿¡åº¦",
                    stats["medium_confidence"],
                )
            with col4:
                st.metric(
                    f"{get_confidence_emoji(0.3)} ä½ç½®ä¿¡åº¦",
                    stats["low_confidence"],
                )
            
            st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{stats['avg_confidence']:.3f}")
            
            # åˆ›å»ºå¯è§†åŒ–å›¾åƒ
            try:
                vis_image = create_visualization(
                    image_path=input_path,
                    detections=detections,
                    thickness=2,
                    show_label=True,
                    show_confidence=True,
                )
                
                # è½¬æ¢ä¸º PIL å›¾åƒç”¨äº Streamlit æ˜¾ç¤º
                pil_image = image_to_pil(vis_image)
                
                # æ˜¾ç¤ºå¯è§†åŒ–ç»“æœ
                st.image(pil_image, use_container_width=True, caption="æ¨ç†ç»“æœå¯è§†åŒ–")
                
                # ä¸‹è½½æŒ‰é’®
                from io import BytesIO
                
                buf = BytesIO()
                pil_image.save(buf, format="PNG")
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½æ¨ç†ç»“æœå›¾åƒ",
                    data=buf.getvalue(),
                    file_name=f"{Path(input_path).stem}_inference.png",
                    mime="image/png",
                )
                
            except Exception as e:
                logger.exception("å¯è§†åŒ–å¤±è´¥")
                st.error(f"å¯è§†åŒ–å¤±è´¥: {str(e)}")
        
        # å‡ ä½•æ ¡æ­£ç»“æœï¼ˆå ä½ï¼‰
        st.header("âœ… å‡ ä½•æ ¡æ­£ç»“æœ")
        if "detections" in st.session_state:
            st.info("å‡ ä½•æ ¡æ­£åŠŸèƒ½å°†åœ¨ Phase 4 ä¸­å®ç°")
        else:
            st.info("è¯·å…ˆè¿è¡Œæ¨ç†ä»¥æŸ¥çœ‹å‡ ä½•æ ¡æ­£ç»“æœ")
    
    else:
        st.info("ğŸ‘† è¯·ä¸Šä¼ ä¸€å¼ å›¾åƒå¼€å§‹å¤„ç†")


if __name__ == "__main__":
    main()

